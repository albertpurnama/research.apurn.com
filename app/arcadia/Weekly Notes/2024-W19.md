---
tags:
  - weekly
---
## Goal

- ~~Fix llm.go tokenizer to use BPE~~
	- After talking to Josh, he recommends watching 3blue1brown deeplearning playlist https://www.youtube.com/watch?v=Ilg3gGewQ5U&ab_channel=3Blue1Brown
- [x] Add downloading I-129 âœ… 2024-05-08

## ðŸ§¨ Tasks
```tasks
not done
(scheduled before 2024-05-05) OR (due before 2024-05-05)
```

## ðŸ“ˆ Stats 
*Things to celebrate on!*

### ðŸ† Tasks completed

| Month                                                                                                                                                                        | Today                                                                                                          |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| `$= dv.pages().file.tasks.where(t => t.completed).where(t => t.text.includes('âœ… ' + new Date(new Date('2024-05-05').setDate(1)).toISOString().slice(0, 7))).length` | `$= dv.pages().file.tasks.where(t => t.completed).where(t => t.text.includes('âœ… 2024-05-05')).length` |


## ðŸªµ Log
*What's on my mind this week?*

Learnings:
- Why engineering?
	- Solving problems through code.
- Application layer seems to be solved atm. General pattern is to:
	- Define the problem well, for example: for Typedream we wanted to help users to build their first website as fast as possible. There are many ways to do this.
	- Think of a few solution, ranges from using thousands of getting started tutorials out there to training your own small model.
	- Pick the easiest solution, for us it is to select the appropriate templates for the website that they are making. Use existing infrastructure, langchain & openai mostly
	- Optimize, break the problem into smaller simpler solution, but not too long, otherwise latency becomes issue. Fine tune smaller models, streaming, etc is definitely a needed.
- Other than the pattern above, things get challenging, but maybe worth exploring:
	- Tuning your own LLM.
- Tips & Tricks:
	- Try to avoid agentic workflows for now because the upside isn't that much compared to basic prompting + breaking up problems into smaller pieces
	- We sometimes do have long chains of prompting that has simple flow through graph, imagine each node is its own LLM. I find this pattern also interesting because it's much more controllable.
- Controlability seems to not be a problem in LLM, but it is in diffusion models



Challenges:
- Evaluations in LLM,how do you define what is a good copywriting? how do you do that at scale? No tools are consistent at this yet.
- 

